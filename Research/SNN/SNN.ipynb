{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cimport numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuron import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "class InputNeuron(object):\n",
    "    \n",
    "    def __init__(self, nnet, spike_train):\n",
    "        self.spike_train = spike_train\n",
    "        self.output_spikes_times = []\n",
    "        self.net = nnet\n",
    "        \n",
    "    def set_spike_train(self, spike_train):\n",
    "        self.spike_train = spike_train\n",
    "        self.output_spikes_times = []\n",
    "        \n",
    "    def step(self):\n",
    "        if self.spike_train[self.net.global_time] == 1:\n",
    "            self.output_spikes_times.append(self.net.global_time)\n",
    "    \n",
    "    def get_spikes(self):\n",
    "        return self.output_spikes_times\n",
    "\n",
    "\n",
    "class Connection(object):\n",
    "    def __init__(self, nnet, input_neuron, output_neuron,\n",
    "                 weights=[1], delays=[1]):  # weights and delays are scaled\n",
    "        self.weights = weights\n",
    "        self.delays = delays\n",
    "        self.input_neuron = input_neuron\n",
    "        self.output_neuron = output_neuron\n",
    "        self.net = nnet\n",
    "        self.last_conducted_spike_index = 0\n",
    "\n",
    "    def step(self):\n",
    "        spikes = self.input_neuron.output_spikes_times\n",
    "        for i in range(self.last_conducted_spike_index, len(spikes)):\n",
    "            spike_time = spikes[i]\n",
    "            for j in range(len(self.weights)):\n",
    "                if spike_time + self.delays[j] == self.net.global_time:\n",
    "                    self.last_conducted_spike_index += 1\n",
    "                    self.output_neuron.receive_spike(self.weights[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function fixed_frequency_spike_train at 0x7faa142d3f28>\n"
     ]
    }
   ],
   "source": [
    "def fixed_frequency_spike_train(frequency, t_max):\n",
    "    actual_frequency = float(frequency)\n",
    "    result = [1 if frequency > 0 else 0]\n",
    "    for i in range(t_max - 1):\n",
    "        if actual_frequency >= 1:\n",
    "            result.append(1)\n",
    "            actual_frequency -= int(actual_frequency)\n",
    "        else:\n",
    "            result.append(0)\n",
    "        actual_frequency += frequency\n",
    "    return result\n",
    "\n",
    "print(fixed_frequency_spike_train)\n",
    "\n",
    "from functools import reduce\n",
    "class InputLayer(object):\n",
    "    def __init__(self, nnet, shape):\n",
    "        self.net = nnet\n",
    "        self.shape = shape \n",
    "        self.neur_size = reduce(lambda res, x: res*x, self.shape, 1)\n",
    "        self.neurons = np.ndarray(shape=self.shape, dtype=InputNeuron, buffer=np.array([InputNeuron(self.net, []) for i in np.arange(self.neur_size)]))\n",
    "            \n",
    "    def random_spike_train(freq, t_max):\n",
    "        return sps.bernoulli.rvs(0.25*freq +0.5, size=t_max)\n",
    "    \n",
    "    def new_input(self, arg, t_max=1000, make_spike_train=fixed_frequency_spike_train):\n",
    "        for i, f in enumerate(arg):\n",
    "            for j, l in enumerate(f):\n",
    "                for k, m in enumerate(l):\n",
    "                    self.neurons[i][j][k].set_spike_train(fixed_frequency_spike_train(arg[i][j][k], t_max))\n",
    "    \n",
    "    def step(self):\n",
    "        for neur in self.neurons.reshape((self.neur_size)):\n",
    "            neur.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Conv2DLayer(object):\n",
    "    # Формат весов: w[nk][h][i][j], где nk - фильтр, h - номер фильтра на предыдущем слое, i, j - координаты весов в фильтре\n",
    "    def __init__(self, nnet, input_layer, num_filters, filter_shape, weights):\n",
    "        self.net = nnet\n",
    "        self.filter_shape = filter_shape\n",
    "        self.weights = self.oldweights = weights.copy() \n",
    "        if(len(self.weights.shape) < 5):\n",
    "            self.weights = self.weights.reshape(np.append(weights.shape, 1))\n",
    "        \n",
    "        self.shape = (num_filters, input_layer.shape[1]-filter_shape[0]+1, input_layer.shape[2]-filter_shape[1]+1)\n",
    "        self.neur_size = reduce(lambda res, x: res*x, self.shape, 1)\n",
    "        self.neurons = np.array([Neuron(self.net) for i in np.arange(self.neur_size)]).reshape(self.shape)\n",
    "        \n",
    "        self.connections = []\n",
    "        \n",
    "        for nk, kernel in enumerate(self.neurons):\n",
    "            for i, row in enumerate(kernel):\n",
    "                for j, neuron in enumerate(row):   # соединяем с предыдущим слоем\n",
    "                    self.connections += [Connection(self.net, input_layer.neurons[l][i+p][j+q],neuron, self.weights[nk][l][p][q])\\\n",
    "                                         for l in np.arange(input_layer.shape[0]) for p in np.arange(filter_shape[0])\\\n",
    "                                         for q in np.arange(filter_shape[1])] \n",
    "                    \n",
    "    def restart(self):\n",
    "        for i, neur in enumerate(self.neurons.reshape((self.neur_size))):\n",
    "            neur.restart()\n",
    "    \n",
    "    def step(self):\n",
    "        for conn in self.connections:\n",
    "            conn.step()\n",
    "        for i, neur in enumerate(self.neurons.reshape((self.neur_size))):\n",
    "            neur.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class SubSampling2DLayer(object):\n",
    "    def __init__(self, nnet, input_layer, pool_size):\n",
    "        self.net = nnet\n",
    "        self.pool_size = pool_size\n",
    "        self.shape = input_layer.shape // np.append([1], pool_size)\n",
    "        self.neur_size = reduce(lambda res, x: res*x, self.shape, 1)\n",
    "        self.neurons = np.array([Neuron(self.net) for i in np.arange(self.neur_size)]).reshape(self.shape)\n",
    "        \n",
    "        self.conn_weight = 1 / (pool_size[0] * pool_size[1])\n",
    "        \n",
    "        self.connections = []\n",
    "        \n",
    "        for nk, kernel in enumerate(self.neurons):\n",
    "            for i, row in enumerate(kernel):\n",
    "                for j, neuron in enumerate(row):   \n",
    "                    self.connections += [Connection(self.net,input_layer.neurons[l][i*pool_size[0]+p][j*pool_size[1]+q],neuron,\\\n",
    "                                                    [self.conn_weight])\\\n",
    "                                         for l in np.arange(input_layer.shape[0]) for p in np.arange(pool_size[0])\\\n",
    "                                         for q in np.arange(pool_size[1])] \n",
    "                    \n",
    "    def restart(self):\n",
    "        for i, neur in enumerate(self.neurons.reshape((self.neur_size))):\n",
    "            neur.restart()\n",
    "        \n",
    "    def step(self):\n",
    "        for conn in self.connections:\n",
    "            conn.step()\n",
    "        for neur in self.neurons.reshape((self.neur_size)):\n",
    "            neur.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pool = ThreadPool(5)\n",
    "class DenseLayer(object):\n",
    "    #Формат весов: w[i][j],  где i - номер нейрона на предыдущем слое, j - номер нейрона на текущем слое\n",
    "    def __init__(self,nnet, input_layer, num_units, weights, threshold=1.):\n",
    "        self.net = nnet\n",
    "        self.shape = [num_units]\n",
    "        self.neur_size = num_units\n",
    "        self.neurons = np.array([Neuron(self.net, threshold) for i in np.arange(self.neur_size)])\n",
    "        self.weights = weights\n",
    "        \n",
    "        if(len(weights.shape) < 3):\n",
    "            weights = weights.reshape(np.append(weights.shape, 1))\n",
    "        \n",
    "        self.connections = [Connection(self.net, input_neuron, output_neuron, weights[i][j])\\\n",
    "                            for i, input_neuron in enumerate(input_layer.neurons.reshape((input_layer.neur_size)))\\\n",
    "                            for j, output_neuron in enumerate(self.neurons)]\n",
    "        \n",
    "    def restart(self):\n",
    "        for neur in self.neurons:\n",
    "            neur.restart()\n",
    "        \n",
    "    def step(self):\n",
    "        #for conn in self.connections:\n",
    "            #conn.step()\n",
    "        list(map(lambda x: x.step(), self.connections)) # POOL\n",
    "        list(map(lambda x: x.step(), self.neurons)) # POOL\n",
    "        #for neur in self.neurons:\n",
    "            #neur.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pool1 = ThreadPool(4)\n",
    "class NNet(object):\n",
    "    def __init__(self, shape, threshold=1.):\n",
    "        self.layers = [InputLayer(self, shape)]\n",
    "        self.global_time = 0\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def add_convolution(self, weights):\n",
    "        num_filters = weights.shape[0]\n",
    "        filter_shape = weights.shape[2:4]\n",
    "        self.layers.append(Conv2DLayer(self, self.layers[-1], num_filters, filter_shape, weights))\n",
    "        \n",
    "    def add_subsampling(self, pool_size):\n",
    "        self.layers.append(SubSampling2DLayer(self, self.layers[-1], pool_size))\n",
    "        \n",
    "    def add_dense(self, weights):\n",
    "        num_units = weights.shape[1]\n",
    "        self.layers.append(DenseLayer(self, self.layers[-1], num_units, weights, threshold=self.threshold))\n",
    "    \n",
    "    def get_output_for(self, data, t_max):\n",
    "        self.global_time = 0\n",
    "        self.layers[0].new_input(data, t_max)\n",
    "        for l in self.layers[1:]:\n",
    "            l.restart()\n",
    "        for t in np.arange(t_max):\n",
    "            #for layer in self.layers:\n",
    "                #layer.step()\n",
    "            list(map(lambda x: x.step(), self.layers)) # POOL\n",
    "            self.global_time += 1\n",
    "        result = [neur.get_spikes() for neur in self.layers[-1].neurons.reshape((self.layers[-1].neur_size))]\n",
    "        return result\n",
    "    \n",
    "    def classify(self, data, t_max):\n",
    "        self.global_time = 0\n",
    "        self.layers[0].new_input(data)\n",
    "        for l in self.layers[1:]:\n",
    "            l.restart()\n",
    "        ans = []\n",
    "        for t in np.arange(t_max):\n",
    "            #for layer in self.layers:\n",
    "                #layer.step()\n",
    "            list(map(lambda x: x.step(), self.layers)) # POOL\n",
    "            for i, neur in enumerate(self.layers[-1].neurons):\n",
    "                if len(neur.get_spikes()) > 0:\n",
    "                    ans.append(i)\n",
    "            if(len(ans) > 0):\n",
    "                return ans, t\n",
    "            self.global_time += 1\n",
    "        print('not_enough_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "\n",
    "def spiking_from_lasagne(input_net, threshold):\n",
    "    input_layers = lasagne.layers.get_all_layers(input_net)\n",
    "    weights = lasagne.layers.get_all_param_values(input_net)\n",
    "    spiking_net = NNet(input_layers[0].shape[-3:], threshold)\n",
    "    convert_layers = {lasagne.layers.conv.Conv2DLayer : spiking_net.add_convolution,\\\n",
    "                      lasagne.layers.dense.DenseLayer : spiking_net.add_dense}\n",
    "    \n",
    "    #номер элемента в общем массиве весов, в котором хранятся веса текущего слоя\n",
    "    i = 0\n",
    "    \n",
    "    for l in input_layers[1:]:\n",
    "        if(type(l) == lasagne.layers.pool.Pool2DLayer or type(l) == lasagne.layers.pool.MaxPool2DLayer):\n",
    "            spiking_net.add_subsampling(l.pool_size)\n",
    "        else:\n",
    "            convert_layers[type(l)](weights[i])\n",
    "            i+=1\n",
    "            \n",
    "    return spiking_net"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
